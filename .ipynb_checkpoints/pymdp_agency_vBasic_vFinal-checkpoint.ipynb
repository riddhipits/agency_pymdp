{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# active inference model of agency task (basic)\n",
    "\n",
    "### prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install inferactively-pymdp\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pymdp\n",
    "\n",
    "from pymdp import utils \n",
    "from pymdp import maths\n",
    "from pymdp.maths import softmax\n",
    "from pymdp.agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### specifying the states and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_names = ['self_positive', 'self_negative', \n",
    "                 'other_positive', 'other_negative', 'zero']\n",
    "choice_self_names = ['start_self', 'Press_self', 'noPress_self']\n",
    "choice_other_names = ['start_other', 'Press_other', 'noPress_other']\n",
    "\n",
    "\"\"\" Define `num_states` and `num_factors` below \"\"\"\n",
    "num_states = [len(context_names), len(choice_self_names), len(choice_other_names)]\n",
    "num_factors = len(num_states)\n",
    "\n",
    "context_action_names = ['no_changes']\n",
    "choice_action_self_names = ['start_self', 'Action_self', 'noAction_self']\n",
    "choice_action_other_names = ['equal_distribution']\n",
    "\n",
    "\"\"\" Define `num_controls` below \"\"\"\n",
    "num_controls = [len(context_action_names), len(choice_action_self_names), len(choice_action_other_names)]\n",
    "\n",
    "outcome_obs_names = ['outcome_start','outcome_present', 'outcome_absent']\n",
    "choice_obs_self_names = ['start_self', 'Press_self', 'noPress_self']\n",
    "choice_obs_other_names = ['start_other', 'Press_other', 'noPress_other']\n",
    "\n",
    "\"\"\" Define `num_obs` and `num_modalities` below \"\"\"\n",
    "num_obs = [len(outcome_obs_names), len(choice_obs_self_names), len(choice_obs_other_names)]\n",
    "num_modalities = len(num_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_A(p_outcome=1.0):\n",
    "    \n",
    "    A = utils.initialize_empty_A(num_obs, num_states)\n",
    "    \n",
    "    '''likelihood matrix for outcome modality'''\n",
    "    \n",
    "    p_outcome = 1.0 # probability of outcome occurring, according to the agent's generative model\n",
    "    \n",
    "    A_outcome = np.zeros( (len(outcome_obs_names), len(context_names), len(choice_self_names), len(choice_other_names)) )\n",
    "    \n",
    "    # P(observation|start_self, start_other)\n",
    "    A_outcome[0,:,0,0] = 1.0\n",
    "    \n",
    "    # P(observation|start_self, Press_other)\n",
    "    A_outcome[0,:,0,1] = 1.0\n",
    "    \n",
    "    # P(observation|start_self, noPress_other)\n",
    "    A_outcome[0,:,0,2] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, start_other)\n",
    "    A_outcome[0,:,1,0] = 1.0\n",
    "    \n",
    "    # P(observation|noPress_self, start_other)\n",
    "    A_outcome[0,:,2,0] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, Press_other)\n",
    "    A_outcome[:,:,1,1] = [[0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                          [p_outcome, 1.0 - p_outcome, p_outcome, 1.0 - p_outcome, .5], \n",
    "                          [1.0 - p_outcome, p_outcome, 1.0 - p_outcome, p_outcome, .5]]\n",
    "    \n",
    "    # P(observation|Press_self, noPress_other)\n",
    "    A_outcome[:,:,1,2] = [[0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                          [p_outcome, 1.0 - p_outcome, 1.0 - p_outcome, p_outcome, .5],\n",
    "                          [1.0 - p_outcome, p_outcome, p_outcome, 1.0 - p_outcome, .5]]\n",
    "    \n",
    "    # P(observation|noPress_self, Press_other)\n",
    "    A_outcome[:,:,2,1] = [[0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                          [1.0 - p_outcome, p_outcome, p_outcome, 1.0 - p_outcome, .5],\n",
    "                          [p_outcome, 1.0 - p_outcome, 1.0 - p_outcome, p_outcome, .5]]\n",
    "    \n",
    "    # P(observation|noPress_self, noPress_other)\n",
    "    A_outcome[:,:,2,2] = [[0.0, 0.0, 0.0, 0.0, 0.0], \n",
    "                          [1.0 - p_outcome, p_outcome, 1.0 - p_outcome, p_outcome, .5],\n",
    "                          [p_outcome, 1.0 - p_outcome, p_outcome, 1.0 - p_outcome, .5]]\n",
    "    \n",
    "    \n",
    "    '''likelihood matrix for agent 1's proprioception modality'''        \n",
    "    A_choice_self = np.zeros((len(choice_obs_self_names), len(context_names), len(choice_self_names), len(choice_other_names)))\n",
    "    \n",
    "    # P(observation|start_self, start_other)\n",
    "    A_choice_self[0,:,0,0] = 1.0\n",
    "    \n",
    "    # P(observation|start_self, Press_other)\n",
    "    A_choice_self[0,:,0,1] = 1.0\n",
    "    \n",
    "    # P(observation|start_self, noPress_other)\n",
    "    A_choice_self[0,:,0,2] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, start_other)\n",
    "    A_choice_self[1,:,1,0] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, Press_other)\n",
    "    A_choice_self[1,:,1,1] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, noPress_other)\n",
    "    A_choice_self[1,:,1,2] = 1.0\n",
    "    \n",
    "    # P(observation|noPress_self, start_other)\n",
    "    A_choice_self[2,:,2,0] = 1.0\n",
    "    \n",
    "    # P(observation|noPress_self, Press_other)\n",
    "    A_choice_self[2,:,2,1] = 1.0\n",
    "    \n",
    "    # P(observation|noPress_self, noPress_other)\n",
    "    A_choice_self[2,:,2,2] = 1.0\n",
    "    \n",
    "    \n",
    "    '''likelihood matrix for agent 2's proprioception modality'''        \n",
    "    A_choice_other = np.zeros((len(choice_obs_other_names), len(context_names), len(choice_self_names), len(choice_other_names)))\n",
    "    \n",
    "    # P(observation|start_self, start_other)\n",
    "    A_choice_other[0,:,0,0] = 1.0\n",
    "    \n",
    "    # P(observation|start_self, Press_other)\n",
    "    A_choice_other[1,:,0,1] = 1.0\n",
    "    \n",
    "    # P(observation|start_self, noPress_other)\n",
    "    A_choice_other[2,:,0,2] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, start_other)\n",
    "    A_choice_other[0,:,1,0] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, Press_other)\n",
    "    A_choice_other[1,:,1,1] = 1.0\n",
    "    \n",
    "    # P(observation|Press_self, noPress_other)\n",
    "    A_choice_other[2,:,1,2] = 1.0\n",
    "    \n",
    "    # P(observation|noPress_self, start_other)\n",
    "    A_choice_other[0,:,2,0] = 1.0\n",
    "    \n",
    "    # P(observation|noPress_self, Press_other)\n",
    "    A_choice_other[1,:,2,1] = 1.0\n",
    "    \n",
    "    # P(observation|noPress_self, noPress_other)\n",
    "    A_choice_other[2,:,2,2] = 1.0\n",
    "        \n",
    "    A[0], A[1], A[2] = A_outcome, A_choice_self, A_choice_other\n",
    "    \n",
    "    return A\n",
    "\n",
    "# A = create_A(p_outcome = 1.0)\n",
    "# utils.plot_likelihood(A[0][:,:,0,0], title = \"Probability of outcome, given nothing\")\n",
    "# utils.plot_likelihood(A[1][:,:,1,2], title = \"Probability of outcome, given humanAction_compAction\")\n",
    "# utils.plot_likelihood(A[0][:,:,2], title = \"Probability of outcome, given humanAction_compNoAction\")\n",
    "# utils.plot_likelihood(A[0][:,:,3], title = \"Probability of outcome, given humanNoAction_compAction\")\n",
    "# utils.plot_likelihood(A[0][:,:,4], title = \"Probability of outcome, given humanNoAction_compNoAction\")\n",
    "# utils.plot_likelihood(A[1][:,0,:], title=\"Mapping between sensed states and true states for Actions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def create_B(p_change = 0.0):\n",
    "    # `p_change`: probability of the context changing\n",
    "    B = utils.initialize_empty_B(num_states, num_states)\n",
    "    \n",
    "    B_context = np.zeros( (len(context_names), len(context_names), len(context_action_names)) )\n",
    "    B_context[:,:,0] = np.eye(len(context_names))\n",
    "    \n",
    "    B_choice_self = np.zeros( (len(choice_self_names), len(choice_self_names), len(choice_action_self_names)) )\n",
    "    \n",
    "    for choice_i in range(len(choice_self_names)):\n",
    "        B_choice_self[choice_i, :, choice_i] = 1.0\n",
    "    \n",
    "    B_choice_other = np.zeros( (len(choice_other_names), len(choice_other_names), len(choice_action_other_names)) )\n",
    "    \n",
    "    for choice_i in range(len(choice_other_names)):\n",
    "        B_choice_other[:,:,0] = np.array(1.0/float(num_states[2]))\n",
    "        \n",
    "    B[0], B[1], B[2] = B_context, B_choice_self, B_choice_other\n",
    "    \n",
    "    return B\n",
    "\n",
    "B = create_B(p_change=0.0)\n",
    "\n",
    "print(B[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_C(reward = 1.0, pun = 0.0, actioncost = 0.0):\n",
    "    \n",
    "    # define reward and punishment values mapping onto outcome_present and outcome_absent preferences\n",
    "    \n",
    "    C = utils.obj_array_zeros(num_obs)\n",
    "    C[0] = np.array([0.0, reward, pun])\n",
    "    C[1] = np.array([0.0, actioncost, 0.0])\n",
    "    C[2] = np.array([0.0, 0.0, 0.0])\n",
    "    \n",
    "    return C\n",
    "\n",
    "# C = create_C(reward = 1.0, pun = 0.0)\n",
    "# utils.plot_beliefs(softmax(C[0]), title = \"Prior preferences for outcome_present and outcome_absent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_D(p_context=1/float(num_states[0])):\n",
    "    \n",
    "    D = utils.obj_array(num_factors)\n",
    "    \n",
    "    D_context = np.ones(num_states[0])/float(num_states[0])\n",
    "    \n",
    "    D_choice_self = np.zeros(len(choice_self_names)) \n",
    "    D_choice_self[choice_self_names.index(\"start_self\")] = 1.0\n",
    "    \n",
    "    D_choice_other = np.zeros(len(choice_other_names)) \n",
    "    D_choice_other[choice_other_names.index(\"start_other\")] = 1.0\n",
    "\n",
    "    D[0], D[1], D[2] = D_context, D_choice_self, D_choice_other\n",
    "    \n",
    "    return D\n",
    "\n",
    "# D = create_D(p_context=1/float(num_states[0]))\n",
    "# utils.plot_beliefs(softmax(D[1]), title = \"Prior beliefs about probability of the contexts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgencyTask(object):\n",
    "    \n",
    "    def __init__(self, context = None, p_action_other = 0.5, p_outcome = 1.0):\n",
    "        \n",
    "        self.context_names = ['self_positive', 'self_negative',\n",
    "                              'other_positive', 'other_negative', 'zero']\n",
    "        if context == None:\n",
    "            self.context = self.context_names[utils.sample(np.ones(num_states[0])/float(num_states[0]))] # randomly sample which context is selected\n",
    "        else:\n",
    "            self.context = context\n",
    "            \n",
    "        self.p_outcome = p_outcome\n",
    "        self.p_action_other = p_action_other\n",
    "        \n",
    "        self.outcome_obs_names = ['outcome_start', 'outcome_present', 'outcome_absent']\n",
    "        \n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        self.action_other_names = ['start_other', 'Action_other', 'noAction_other']\n",
    "        self.action_other = self.action_other_names[utils.sample(np.array([0.0, self.p_action_other, 1.0-self.p_action_other]))]\n",
    "        \n",
    "        if action == \"start_self\" and self.action_other == \"start_other\":\n",
    "            observed_choice_self = \"start_self\"\n",
    "            observed_choice_other = \"start_other\"\n",
    "            observed_outcome = \"outcome_start\"\n",
    "                \n",
    "        elif action == \"Action_self\" and self.action_other == \"Action_other\":\n",
    "            observed_choice_self = \"Press_self\"\n",
    "            observed_choice_other = \"Press_other\"\n",
    "            \n",
    "            if self.context == \"self_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"self_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"other_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"other_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"zero\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 0.5, 0.5]))]\n",
    "                \n",
    "        elif action == \"Action_self\" and self.action_other == \"noAction_other\":\n",
    "            observed_choice_self = \"Press_self\"\n",
    "            observed_choice_other = \"noPress_other\"\n",
    "            \n",
    "            if self.context == \"self_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"self_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"other_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"other_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"zero\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 0.5, 0.5]))]\n",
    "                \n",
    "        elif action == \"noAction_self\" and self.action_other == \"Action_other\":\n",
    "            observed_choice_self = \"noPress_self\"\n",
    "            observed_choice_other = \"Press_other\"\n",
    "            \n",
    "            if self.context == \"self_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"self_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"other_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"other_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"zero\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 0.5, 0.5]))]\n",
    "                \n",
    "        elif action == \"noAction_self\" and self.action_other == \"noAction_other\":\n",
    "            observed_choice_self = \"noPress_self\"\n",
    "            observed_choice_other = \"noPress_other\"\n",
    "            \n",
    "            if self.context == \"self_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"self_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"other_positive\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 1.0-self.p_outcome, self.p_outcome]))]\n",
    "            elif self.context == \"other_negative\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, self.p_outcome, 1.0-self.p_outcome]))]\n",
    "            elif self.context == \"zero\":\n",
    "                observed_outcome = self.outcome_obs_names[utils.sample(np.array([0.0, 0.5, 0.5]))]\n",
    "\n",
    "        obs = [observed_outcome, observed_choice_self, observed_choice_other]\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_active_inference_loop(my_agent, my_env, T = 5, verbose = False):\n",
    "    \n",
    "    \"\"\" Initialize the first observation \"\"\"\n",
    "    obs_label = [\"outcome_start\", \"start_self\", \"start_other\"]  \n",
    "    obs = [outcome_obs_names.index(obs_label[0]), choice_obs_self_names.index(obs_label[1]), choice_obs_other_names.index(obs_label[2])]\n",
    "    \n",
    "    first_choice = choice_obs_self_names.index(obs_label[1])\n",
    "    choice_hist = np.zeros((3,T+1))\n",
    "    choice_hist[first_choice,0] = 1.0\n",
    "    \n",
    "    belief_hist = np.zeros((5, T))\n",
    "    belief_action_self_hist = np.zeros((3, T))\n",
    "    belief_action_other_hist = np.zeros((3, T))\n",
    "    context_hist = np.zeros(T)\n",
    "    \n",
    "    for t in range(T):\n",
    "        context_hist[t] = env.context_names.index(env.context)\n",
    "        qs = my_agent.infer_states(obs)\n",
    "        \n",
    "        belief_hist[:,t] = qs[0]\n",
    "        belief_action_self_hist[:,t] = qs[1]\n",
    "        belief_action_other_hist[:,t] = qs[2]\n",
    "        \n",
    "        if verbose:\n",
    "             utils.plot_beliefs(qs[0], title = f\"Beliefs about the context at time {t}\")\n",
    "#             utils.plot_beliefs(qs[1], title = f\"Beliefs about the action_self at time {t}\")\n",
    "#             utils.plot_beliefs(qs[2], title = f\"Beliefs about the action_other at time {t}\")\n",
    "            \n",
    "        q_pi, efe = my_agent.infer_policies()\n",
    "        chosen_action_id = my_agent.sample_action()\n",
    "        \n",
    "        movement_id = int(chosen_action_id[1])\n",
    "        choice_hist[movement_id,t+1]= 1.0\n",
    "        \n",
    "        choice_action = choice_action_self_names[movement_id]\n",
    "        \n",
    "        obs_label = my_env.step(choice_action)\n",
    "        \n",
    "        obs = [outcome_obs_names.index(obs_label[0]), choice_obs_self_names.index(obs_label[1]), choice_obs_other_names.index(obs_label[2])]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'Action at time {t}: {choice_action}')\n",
    "            print(f'Outcome at time {t}: {obs_label[0]}')\n",
    "            print(f'Obs_action_self at time {t}: {obs_label[1]}')\n",
    "            print(f'Obs_action_other at time {t}: {obs_label[2]}')\n",
    "\n",
    "    return choice_hist, belief_hist, context_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_choices_beliefs(choice_hist, belief_hist, context_hist, pad_val=5.0):\n",
    "    T = choice_hist.shape[1]\n",
    "    fig, axes = plt.subplots(nrows = 2, ncols = 1, figsize = (15,13))\n",
    "    \n",
    "    axes[0].imshow(choice_hist[:,:-1], cmap = 'gray') \n",
    "    axes[0].set_xlabel('Timesteps')\n",
    "    axes[0].set_yticks(ticks = range(3))\n",
    "    axes[0].set_yticklabels(labels = choice_action_self_names)\n",
    "    axes[0].set_title('Choices over time')\n",
    "    \n",
    "    axes[1].imshow(belief_hist, cmap = 'gray')\n",
    "    axes[1].set_xlabel('Timesteps')\n",
    "    axes[1].set_yticks(ticks = range(5))\n",
    "    axes[1].set_yticklabels(labels = context_names)\n",
    "    axes[1].set_title('Beliefs over time')\n",
    "    axes[1].scatter(np.arange(T-1), context_hist, c = 'r', s = 50)\n",
    "    \n",
    "    fig.tight_layout(pad=pad_val)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_outcome_env = 1.0\n",
    "p_action_other_env = 0.5\n",
    "\n",
    "env = AgencyTask(p_action_other = p_action_other_env, p_outcome = p_outcome_env)\n",
    "\n",
    "T = 15\n",
    "\n",
    "A = create_A(p_outcome = 1.0)\n",
    "B = create_B(p_change = 0.0)\n",
    "C = create_C(reward = 1.0, pun = 0.0, actioncost = -0.5)\n",
    "D = create_D(p_context=1/float(num_states[0]))\n",
    "my_agent = Agent(A=A, B=B, C=C, D=D)\n",
    "\n",
    "choice_hist, belief_hist, context_hist = run_active_inference_loop(my_agent, env, T = T, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'choice_action_agt1_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5e94c9ac2aac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_choices_beliefs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbelief_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-a26705f569d3>\u001b[0m in \u001b[0;36mplot_choices_beliefs\u001b[0;34m(choice_hist, belief_hist, context_hist, pad_val)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timesteps'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoice_action_agt1_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Choices over time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'choice_action_agt1_names' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x936 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_choices_beliefs(choice_hist, belief_hist, context_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
